{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14b090ef",
   "metadata": {},
   "source": [
    "```Aviso: Realize a atividade prática antes de responder o questionário, pois o mesmo faz algumas questões sobre a prática.```\n",
    "\n",
    "### Dataset\n",
    "O dataset spambase  possui 58 atributos preditivos e uma classe binária no qual o valor 1 indica spam e o valor 0 um e-mail comum. Os atributos preditivos são resultados do pré-processamento dos e-mails e contem a frequência de algumas palavras e também características como proporção de letras maiúsculas, etc.\n",
    "\n",
    "Mais detalhe sobre o dataset por ser encontrado em: [https://www.openml.org/search?type=data&id=44&sort=runs&status=active](https://www.openml.org/search?type=data&id=44&sort=runs&status=active)\n",
    "\n",
    " \n",
    "Para as atividades de 1 a 4 execute validação cruzada com 10-folds, para a atividade 5 utilize todo o dataset como conjunto de treinamento.\n",
    "\n",
    "### Atividades práticas\n",
    "* Compare a medida F1 obtida pelos 4 algoritmos apresentados em aula usando suas configurações padrão (sem mudar nenhum hiperparâmetro). *Para evitar warnings de execução do algoritmo Regressão Logistica defina (max_iter=3000).\n",
    "* Execute o K-NN testando os valores de k=3, 5, 7 e 9 e analise o resultado da medida de precisão e revocação.\n",
    "* Calcule a acurácia do modelo de árvore de decisão quando a altura máxima da árvore é definido para 5.\n",
    "* Calcule a medida AUC para o algoritmo SVM usando a combinação de hyperparâmetros: C=0.1 e gamma=0.1.\n",
    "* Usando o algoritmo de Regressão Logística com o datataset inteiro identifique qual é o atributo mais importante segundo os valores dos coeficientes. *Para evitar warnings de execução do algoritmo Regressão Logistica defina (max_iter=3000).**Use os valores absolutos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc0bf7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "177f8813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_%3B</th>\n",
       "      <th>char_freq_%28</th>\n",
       "      <th>char_freq_%5B</th>\n",
       "      <th>char_freq_%21</th>\n",
       "      <th>char_freq_%24</th>\n",
       "      <th>char_freq_%23</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_%3B  char_freq_%28  \\\n",
       "0             0.00            0.00  ...           0.00          0.000   \n",
       "1             0.00            0.94  ...           0.00          0.132   \n",
       "2             0.64            0.25  ...           0.01          0.143   \n",
       "3             0.31            0.63  ...           0.00          0.137   \n",
       "4             0.31            0.63  ...           0.00          0.135   \n",
       "\n",
       "   char_freq_%5B  char_freq_%21  char_freq_%24  char_freq_%23  \\\n",
       "0            0.0          0.778          0.000          0.000   \n",
       "1            0.0          0.372          0.180          0.048   \n",
       "2            0.0          0.276          0.184          0.010   \n",
       "3            0.0          0.137          0.000          0.000   \n",
       "4            0.0          0.135          0.000          0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  class  \n",
       "0                       278      1  \n",
       "1                      1028      1  \n",
       "2                      2259      1  \n",
       "3                       191      1  \n",
       "4                       191      1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./spambase.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a664c108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45700c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['class'])\n",
    "Y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94288497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier() 0.7768480750255765\n",
      "LogisticRegression(max_iter=3000) 0.9144394892117331\n",
      "DecisionTreeClassifier() 0.8957573254558431\n",
      "SVC() 0.6696154584522886\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "lreg = LogisticRegression(max_iter=3000)\n",
    "dt = DecisionTreeClassifier()\n",
    "svm = SVC()\n",
    "\n",
    "for model in [knn, lreg, dt, svm]:\n",
    "    scores = cross_val_score(model, X, Y, cv=10, scoring='f1_macro')\n",
    "    print(model, scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "622318ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85       837\n",
      "           1       0.77      0.77      0.77       544\n",
      "\n",
      "    accuracy                           0.82      1381\n",
      "   macro avg       0.81      0.81      0.81      1381\n",
      "weighted avg       0.82      0.82      0.82      1381\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.84       837\n",
      "           1       0.77      0.74      0.75       544\n",
      "\n",
      "    accuracy                           0.81      1381\n",
      "   macro avg       0.80      0.80      0.80      1381\n",
      "weighted avg       0.81      0.81      0.81      1381\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       837\n",
      "           1       0.76      0.73      0.75       544\n",
      "\n",
      "    accuracy                           0.80      1381\n",
      "   macro avg       0.80      0.79      0.79      1381\n",
      "weighted avg       0.80      0.80      0.80      1381\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       837\n",
      "           1       0.76      0.72      0.74       544\n",
      "\n",
      "    accuracy                           0.80      1381\n",
      "   macro avg       0.79      0.79      0.79      1381\n",
      "weighted avg       0.80      0.80      0.80      1381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, stratify=Y)\n",
    "for i in [3, 5, 7, 9]:\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(x_train, y_train)\n",
    "    y_pred = knn.predict(x_test)\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb7a5ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=5) 0.9026261435442798\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=5)\n",
    "scores = cross_val_score(dt, X, Y, cv=10, scoring='accuracy')\n",
    "print(dt, scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19d96a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=5) 0.924463912901242\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(C=0.1, gamma=0.1)\n",
    "scores = cross_val_score(dt, X, Y, cv=10, scoring='roc_auc')\n",
    "print(dt, scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3c1b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.9369725 , 2.18577869, 2.09792989, 1.33298601, 1.02006995])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TOP 5 best coefs\n",
    "lreg = LogisticRegression(max_iter=3000)\n",
    "lreg.fit(X, Y)\n",
    "np.sort(lreg.coef_.flatten())[::-1][:5]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
