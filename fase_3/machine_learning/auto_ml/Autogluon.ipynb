{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ys9kZOZ6awYe"
      },
      "source": [
        "# Especialização em Inteligência Artificial\n",
        "\n",
        "\n",
        "**Aprendizado de Máquina - Web Conf 2: Exemplo de AutoML com AutoGluon**\n",
        "\n",
        "Código de exemplo desenvolvido pelo docente [Adriano Rivolli](mailto:rivolli@utpfr.edu.br)\n",
        "\n",
        "*O código a seguir ilustra um exemplo da ferramenta AutoGluon*\n",
        "\n",
        "- Site oficial:\n",
        "https://auto.gluon.ai\n",
        "\n",
        "- Material Adaptado de:\n",
        "https://auto.gluon.ai/stable/tutorials/tabular/index.html\n",
        "\n",
        "- Artigo de referência:\n",
        "https://arxiv.org/abs/2003.06505"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiKJBBK4YD7x",
        "outputId": "a088e03b-0232-4cc1-91e8-8f074a2b6780"
      },
      "source": [
        "#### Instalação do Auto-Gluon\n",
        "\n",
        "```pip\n",
        "!pip install autogluon\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hLQMNXvqdPU2"
      },
      "outputs": [],
      "source": [
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "\n",
        "train_url = 'https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv'\n",
        "test_url = 'https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv'\n",
        "\n",
        "train_data = TabularDataset(train_url)\n",
        "test_data = TabularDataset(test_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "q1yoQFizhPl0",
        "outputId": "ffa4be34-a613-42cd-e089-490b8f9d2b23"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>Private</td>\n",
              "      <td>178478</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Tech-support</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>23</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>61743</td>\n",
              "      <td>5th-6th</td>\n",
              "      <td>3</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Transport-moving</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>46</td>\n",
              "      <td>Private</td>\n",
              "      <td>376789</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Other-service</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>55</td>\n",
              "      <td>?</td>\n",
              "      <td>200235</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>?</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36</td>\n",
              "      <td>Private</td>\n",
              "      <td>224541</td>\n",
              "      <td>7th-8th</td>\n",
              "      <td>4</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>El-Salvador</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age   workclass  fnlwgt   education  education-num       marital-status  \\\n",
              "0   25     Private  178478   Bachelors             13        Never-married   \n",
              "1   23   State-gov   61743     5th-6th              3        Never-married   \n",
              "2   46     Private  376789     HS-grad              9        Never-married   \n",
              "3   55           ?  200235     HS-grad              9   Married-civ-spouse   \n",
              "4   36     Private  224541     7th-8th              4   Married-civ-spouse   \n",
              "\n",
              "           occupation    relationship    race      sex  capital-gain  \\\n",
              "0        Tech-support       Own-child   White   Female             0   \n",
              "1    Transport-moving   Not-in-family   White     Male             0   \n",
              "2       Other-service   Not-in-family   White     Male             0   \n",
              "3                   ?         Husband   White     Male             0   \n",
              "4   Handlers-cleaners         Husband   White     Male             0   \n",
              "\n",
              "   capital-loss  hours-per-week  native-country   class  \n",
              "0             0              40   United-States   <=50K  \n",
              "1             0              35   United-States   <=50K  \n",
              "2             0              15   United-States   <=50K  \n",
              "3             0              50   United-States    >50K  \n",
              "4             0              40     El-Salvador   <=50K  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "lU5PY8SQdgJF",
        "outputId": "71f4cac2-40da-465c-a583-f65405e06be7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "class\n",
              "<=50K    29704\n",
              ">50K      9369\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label = 'class'\n",
        "train_data[label].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xPcl2YVGdojO",
        "outputId": "6fc2231d-487b-42d2-b1a2-84c057340340"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels\\ag-20251013_071105\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.4.0\n",
            "Python Version:     3.12.10\n",
            "Operating System:   Windows\n",
            "Platform Machine:   AMD64\n",
            "Platform Version:   10.0.26100\n",
            "CPU Count:          12\n",
            "Memory Avail:       18.51 GB / 31.91 GB (58.0%)\n",
            "Disk Space Avail:   185.80 GB / 476.00 GB (39.0%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
            "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
            "Using hyperparameters preset: hyperparameters='default'\n",
            "Beginning AutoGluon training ... Time limit = 120s\n",
            "AutoGluon will save models to \"c:\\AI\\postgrad-ai\\fase_3\\machine_learning\\auto_ml\\AutogluonModels\\ag-20251013_071105\"\n",
            "Train Data Rows:    39073\n",
            "Train Data Columns: 14\n",
            "Label Column:       class\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  [' <=50K', ' >50K']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    18953.95 MB\n",
            "\tTrain Data (Original)  Memory Usage: 19.48 MB (0.1% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('int', ['bool']) : 1 | ['sex']\n",
            "\t0.2s = Fit runtime\n",
            "\t14 features in original data used to generate 14 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 2.09 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.19s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.0639828014229775, Train Rows: 36573, Val Rows: 2500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "}\n",
            "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT ... Training model for up to 119.81s of the 119.81s of remaining time.\n",
            "\tFitting with cpus=6, gpus=0, mem=0.0/18.5 GB\n",
            "\t0.8792\t = Validation score   (accuracy)\n",
            "\t0.62s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBM ... Training model for up to 119.17s of the 119.17s of remaining time.\n",
            "\tFitting with cpus=6, gpus=0, mem=0.0/18.5 GB\n",
            "\t0.8824\t = Validation score   (accuracy)\n",
            "\t0.57s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ... Training model for up to 118.41s of the 118.41s of remaining time.\n",
            "\tFitting with cpus=12, gpus=0, mem=0.0/18.5 GB\n",
            "\t0.8612\t = Validation score   (accuracy)\n",
            "\t1.27s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ... Training model for up to 116.90s of the 116.90s of remaining time.\n",
            "\tFitting with cpus=12, gpus=0, mem=0.0/18.2 GB\n",
            "\t0.8592\t = Validation score   (accuracy)\n",
            "\t1.46s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: CatBoost ... Training model for up to 115.23s of the 115.23s of remaining time.\n",
            "\tFitting with cpus=6, gpus=0\n",
            "\t0.8824\t = Validation score   (accuracy)\n",
            "\t14.98s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ... Training model for up to 100.23s of the 100.23s of remaining time.\n",
            "\tFitting with cpus=12, gpus=0, mem=0.0/18.2 GB\n",
            "\t0.8528\t = Validation score   (accuracy)\n",
            "\t0.88s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ... Training model for up to 99.05s of the 99.05s of remaining time.\n",
            "\tFitting with cpus=12, gpus=0, mem=0.0/17.7 GB\n",
            "\t0.852\t = Validation score   (accuracy)\n",
            "\t0.99s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ... Training model for up to 97.75s of the 97.75s of remaining time.\n",
            "\tFitting with cpus=6, gpus=0, mem=0.0/17.3 GB\n",
            "No improvement since epoch 9: early stopping\n",
            "\t0.8612\t = Validation score   (accuracy)\n",
            "\t27.18s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ... Training model for up to 70.51s of the 70.51s of remaining time.\n",
            "\tFitting with cpus=6, gpus=0\n",
            "\t0.8848\t = Validation score   (accuracy)\n",
            "\t0.6s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ... Training model for up to 69.89s of the 69.89s of remaining time.\n",
            "\tFitting with cpus=6, gpus=0, mem=0.0/18.7 GB\n",
            "c:\\AI\\postgrad-ai\\.venv\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "\t0.8576\t = Validation score   (accuracy)\n",
            "\t37.15s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ... Training model for up to 32.72s of the 32.72s of remaining time.\n",
            "\tFitting with cpus=6, gpus=0, mem=0.0/19.0 GB\n",
            "\t0.8824\t = Validation score   (accuracy)\n",
            "\t0.68s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 119.81s of the 31.94s of remaining time.\n",
            "\tEnsemble Weights: {'XGBoost': 1.0}\n",
            "\t0.8848\t = Validation score   (accuracy)\n",
            "\t0.07s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 88.17s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 209794.9 rows/s (2500 batch size)\n",
            "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (2500 rows).\n",
            "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\AI\\postgrad-ai\\fase_3\\machine_learning\\auto_ml\\AutogluonModels\\ag-20251013_071105\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "class\n",
              "<=50K    7869\n",
              ">50K     1900\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Treinando por 2 minutos\n",
        "predictor = TabularPredictor(label=label).fit(train_data, time_limit=120)\n",
        "y_pred = predictor.predict(test_data.drop(columns=[label]))\n",
        "y_pred.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7r-xNysdfQoB",
        "outputId": "96f752b1-43b2-4ffd-a4c9-6ef499f52486"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.90      0.95      0.92      7451\n",
            "        >50K       0.79      0.65      0.71      2318\n",
            "\n",
            "    accuracy                           0.88      9769\n",
            "   macro avg       0.84      0.80      0.82      9769\n",
            "weighted avg       0.87      0.88      0.87      9769\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(test_data[label], y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "OkQ2AneUmTqn",
        "outputId": "cf2b58a8-0eb5-4f66-dace-1704f9f12daf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_test</th>\n",
              "      <th>score_val</th>\n",
              "      <th>eval_metric</th>\n",
              "      <th>pred_time_test</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_test_marginal</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.876139</td>\n",
              "      <td>0.8848</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.033493</td>\n",
              "      <td>0.008898</td>\n",
              "      <td>0.564189</td>\n",
              "      <td>0.033493</td>\n",
              "      <td>0.008898</td>\n",
              "      <td>0.564189</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>WeightedEnsemble_L2</td>\n",
              "      <td>0.876139</td>\n",
              "      <td>0.8848</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.036997</td>\n",
              "      <td>0.009901</td>\n",
              "      <td>0.659667</td>\n",
              "      <td>0.003504</td>\n",
              "      <td>0.001003</td>\n",
              "      <td>0.095478</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LightGBMLarge</td>\n",
              "      <td>0.875422</td>\n",
              "      <td>0.8824</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.041423</td>\n",
              "      <td>0.009531</td>\n",
              "      <td>0.749856</td>\n",
              "      <td>0.041423</td>\n",
              "      <td>0.009531</td>\n",
              "      <td>0.749856</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>0.874399</td>\n",
              "      <td>0.8824</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.034153</td>\n",
              "      <td>0.004666</td>\n",
              "      <td>15.910002</td>\n",
              "      <td>0.034153</td>\n",
              "      <td>0.004666</td>\n",
              "      <td>15.910002</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LightGBM</td>\n",
              "      <td>0.873477</td>\n",
              "      <td>0.8824</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.023490</td>\n",
              "      <td>0.009215</td>\n",
              "      <td>0.505479</td>\n",
              "      <td>0.023490</td>\n",
              "      <td>0.009215</td>\n",
              "      <td>0.505479</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LightGBMXT</td>\n",
              "      <td>0.871430</td>\n",
              "      <td>0.8792</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.039079</td>\n",
              "      <td>0.012777</td>\n",
              "      <td>5.615748</td>\n",
              "      <td>0.039079</td>\n",
              "      <td>0.012777</td>\n",
              "      <td>5.615748</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RandomForestGini</td>\n",
              "      <td>0.859351</td>\n",
              "      <td>0.8612</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.290134</td>\n",
              "      <td>0.050318</td>\n",
              "      <td>1.578749</td>\n",
              "      <td>0.290134</td>\n",
              "      <td>0.050318</td>\n",
              "      <td>1.578749</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NeuralNetTorch</td>\n",
              "      <td>0.858532</td>\n",
              "      <td>0.8576</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.070374</td>\n",
              "      <td>0.013838</td>\n",
              "      <td>40.698632</td>\n",
              "      <td>0.070374</td>\n",
              "      <td>0.013838</td>\n",
              "      <td>40.698632</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RandomForestEntr</td>\n",
              "      <td>0.857713</td>\n",
              "      <td>0.8592</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.319760</td>\n",
              "      <td>0.049396</td>\n",
              "      <td>1.560209</td>\n",
              "      <td>0.319760</td>\n",
              "      <td>0.049396</td>\n",
              "      <td>1.560209</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>NeuralNetFastAI</td>\n",
              "      <td>0.857406</td>\n",
              "      <td>0.8612</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.505786</td>\n",
              "      <td>0.022529</td>\n",
              "      <td>27.226740</td>\n",
              "      <td>0.505786</td>\n",
              "      <td>0.022529</td>\n",
              "      <td>27.226740</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ExtraTreesGini</td>\n",
              "      <td>0.853414</td>\n",
              "      <td>0.8528</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.375738</td>\n",
              "      <td>0.049844</td>\n",
              "      <td>0.938210</td>\n",
              "      <td>0.375738</td>\n",
              "      <td>0.049844</td>\n",
              "      <td>0.938210</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ExtraTreesEntr</td>\n",
              "      <td>0.850650</td>\n",
              "      <td>0.8520</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.460118</td>\n",
              "      <td>0.050973</td>\n",
              "      <td>0.920979</td>\n",
              "      <td>0.460118</td>\n",
              "      <td>0.050973</td>\n",
              "      <td>0.920979</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  model  score_test  score_val eval_metric  pred_time_test  \\\n",
              "0               XGBoost    0.876139     0.8848    accuracy        0.033493   \n",
              "1   WeightedEnsemble_L2    0.876139     0.8848    accuracy        0.036997   \n",
              "2         LightGBMLarge    0.875422     0.8824    accuracy        0.041423   \n",
              "3              CatBoost    0.874399     0.8824    accuracy        0.034153   \n",
              "4              LightGBM    0.873477     0.8824    accuracy        0.023490   \n",
              "5            LightGBMXT    0.871430     0.8792    accuracy        0.039079   \n",
              "6      RandomForestGini    0.859351     0.8612    accuracy        0.290134   \n",
              "7        NeuralNetTorch    0.858532     0.8576    accuracy        0.070374   \n",
              "8      RandomForestEntr    0.857713     0.8592    accuracy        0.319760   \n",
              "9       NeuralNetFastAI    0.857406     0.8612    accuracy        0.505786   \n",
              "10       ExtraTreesGini    0.853414     0.8528    accuracy        0.375738   \n",
              "11       ExtraTreesEntr    0.850650     0.8520    accuracy        0.460118   \n",
              "\n",
              "    pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
              "0        0.008898   0.564189                 0.033493                0.008898   \n",
              "1        0.009901   0.659667                 0.003504                0.001003   \n",
              "2        0.009531   0.749856                 0.041423                0.009531   \n",
              "3        0.004666  15.910002                 0.034153                0.004666   \n",
              "4        0.009215   0.505479                 0.023490                0.009215   \n",
              "5        0.012777   5.615748                 0.039079                0.012777   \n",
              "6        0.050318   1.578749                 0.290134                0.050318   \n",
              "7        0.013838  40.698632                 0.070374                0.013838   \n",
              "8        0.049396   1.560209                 0.319760                0.049396   \n",
              "9        0.022529  27.226740                 0.505786                0.022529   \n",
              "10       0.049844   0.938210                 0.375738                0.049844   \n",
              "11       0.050973   0.920979                 0.460118                0.050973   \n",
              "\n",
              "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
              "0            0.564189            1       True          9  \n",
              "1            0.095478            2       True         12  \n",
              "2            0.749856            1       True         11  \n",
              "3           15.910002            1       True          5  \n",
              "4            0.505479            1       True          2  \n",
              "5            5.615748            1       True          1  \n",
              "6            1.578749            1       True          3  \n",
              "7           40.698632            1       True         10  \n",
              "8            1.560209            1       True          4  \n",
              "9           27.226740            1       True          8  \n",
              "10           0.938210            1       True          6  \n",
              "11           0.920979            1       True          7  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.leaderboard(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0fo0hSVnDNO",
        "outputId": "cd512077-d1ce-44e7-fdbe-5bad94fa58c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                  model  score_val eval_metric  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0               XGBoost     0.8848    accuracy       0.008898   0.564189                0.008898           0.564189            1       True          9\n",
            "1   WeightedEnsemble_L2     0.8848    accuracy       0.009901   0.659667                0.001003           0.095478            2       True         12\n",
            "2              CatBoost     0.8824    accuracy       0.004666  15.910002                0.004666          15.910002            1       True          5\n",
            "3              LightGBM     0.8824    accuracy       0.009215   0.505479                0.009215           0.505479            1       True          2\n",
            "4         LightGBMLarge     0.8824    accuracy       0.009531   0.749856                0.009531           0.749856            1       True         11\n",
            "5            LightGBMXT     0.8792    accuracy       0.012777   5.615748                0.012777           5.615748            1       True          1\n",
            "6       NeuralNetFastAI     0.8612    accuracy       0.022529  27.226740                0.022529          27.226740            1       True          8\n",
            "7      RandomForestGini     0.8612    accuracy       0.050318   1.578749                0.050318           1.578749            1       True          3\n",
            "8      RandomForestEntr     0.8592    accuracy       0.049396   1.560209                0.049396           1.560209            1       True          4\n",
            "9        NeuralNetTorch     0.8576    accuracy       0.013838  40.698632                0.013838          40.698632            1       True         10\n",
            "10       ExtraTreesGini     0.8528    accuracy       0.049844   0.938210                0.049844           0.938210            1       True          6\n",
            "11       ExtraTreesEntr     0.8520    accuracy       0.050973   0.920979                0.050973           0.920979            1       True          7\n",
            "Number of models trained: 12\n",
            "Types of models trained:\n",
            "{'CatBoostModel', 'XGBoostModel', 'NNFastAiTabularModel', 'LGBModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'XTModel', 'RFModel'}\n",
            "Bagging used: False \n",
            "Multi-layer stack-ensembling used: False \n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "('int', ['bool']) : 1 | ['sex']\n",
            "*** End of fit() summary ***\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\AI\\postgrad-ai\\.venv\\Lib\\site-packages\\autogluon\\core\\utils\\plots.py:169: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
            "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'model_types': {'LightGBMXT': 'LGBModel',\n",
              "  'LightGBM': 'LGBModel',\n",
              "  'RandomForestGini': 'RFModel',\n",
              "  'RandomForestEntr': 'RFModel',\n",
              "  'CatBoost': 'CatBoostModel',\n",
              "  'ExtraTreesGini': 'XTModel',\n",
              "  'ExtraTreesEntr': 'XTModel',\n",
              "  'NeuralNetFastAI': 'NNFastAiTabularModel',\n",
              "  'XGBoost': 'XGBoostModel',\n",
              "  'NeuralNetTorch': 'TabularNeuralNetTorchModel',\n",
              "  'LightGBMLarge': 'LGBModel',\n",
              "  'WeightedEnsemble_L2': 'WeightedEnsembleModel'},\n",
              " 'model_performance': {'LightGBMXT': 0.8792,\n",
              "  'LightGBM': 0.8824,\n",
              "  'RandomForestGini': 0.8612,\n",
              "  'RandomForestEntr': 0.8592,\n",
              "  'CatBoost': 0.8824,\n",
              "  'ExtraTreesGini': 0.8528,\n",
              "  'ExtraTreesEntr': 0.852,\n",
              "  'NeuralNetFastAI': 0.8612,\n",
              "  'XGBoost': 0.8848,\n",
              "  'NeuralNetTorch': 0.8576,\n",
              "  'LightGBMLarge': 0.8824,\n",
              "  'WeightedEnsemble_L2': 0.8848},\n",
              " 'model_best': 'WeightedEnsemble_L2',\n",
              " 'model_paths': {'LightGBMXT': ['LightGBMXT'],\n",
              "  'LightGBM': ['LightGBM'],\n",
              "  'RandomForestGini': ['RandomForestGini'],\n",
              "  'RandomForestEntr': ['RandomForestEntr'],\n",
              "  'CatBoost': ['CatBoost'],\n",
              "  'ExtraTreesGini': ['ExtraTreesGini'],\n",
              "  'ExtraTreesEntr': ['ExtraTreesEntr'],\n",
              "  'NeuralNetFastAI': ['NeuralNetFastAI'],\n",
              "  'XGBoost': ['XGBoost'],\n",
              "  'NeuralNetTorch': ['NeuralNetTorch'],\n",
              "  'LightGBMLarge': ['LightGBMLarge'],\n",
              "  'WeightedEnsemble_L2': ['WeightedEnsemble_L2']},\n",
              " 'model_fit_times': {'LightGBMXT': 5.615748167037964,\n",
              "  'LightGBM': 0.5054788589477539,\n",
              "  'RandomForestGini': 1.5787489414215088,\n",
              "  'RandomForestEntr': 1.5602085590362549,\n",
              "  'CatBoost': 15.91000247001648,\n",
              "  'ExtraTreesGini': 0.9382102489471436,\n",
              "  'ExtraTreesEntr': 0.9209785461425781,\n",
              "  'NeuralNetFastAI': 27.22674036026001,\n",
              "  'XGBoost': 0.5641894340515137,\n",
              "  'NeuralNetTorch': 40.69863224029541,\n",
              "  'LightGBMLarge': 0.7498562335968018,\n",
              "  'WeightedEnsemble_L2': 0.09547805786132812},\n",
              " 'model_pred_times': {'LightGBMXT': 0.012777090072631836,\n",
              "  'LightGBM': 0.009215116500854492,\n",
              "  'RandomForestGini': 0.05031847953796387,\n",
              "  'RandomForestEntr': 0.04939603805541992,\n",
              "  'CatBoost': 0.0046656131744384766,\n",
              "  'ExtraTreesGini': 0.049843788146972656,\n",
              "  'ExtraTreesEntr': 0.05097341537475586,\n",
              "  'NeuralNetFastAI': 0.022528886795043945,\n",
              "  'XGBoost': 0.008898258209228516,\n",
              "  'NeuralNetTorch': 0.013838052749633789,\n",
              "  'LightGBMLarge': 0.009530782699584961,\n",
              "  'WeightedEnsemble_L2': 0.0010027885437011719},\n",
              " 'num_bag_folds': 0,\n",
              " 'max_stack_level': 2,\n",
              " 'num_classes': 2,\n",
              " 'model_hyperparams': {'LightGBMXT': {'learning_rate': 0.05,\n",
              "   'extra_trees': True},\n",
              "  'LightGBM': {'learning_rate': 0.05},\n",
              "  'RandomForestGini': {'n_estimators': 300,\n",
              "   'max_leaf_nodes': 15000,\n",
              "   'n_jobs': -1,\n",
              "   'random_state': 0,\n",
              "   'bootstrap': True,\n",
              "   'criterion': 'gini'},\n",
              "  'RandomForestEntr': {'n_estimators': 300,\n",
              "   'max_leaf_nodes': 15000,\n",
              "   'n_jobs': -1,\n",
              "   'random_state': 0,\n",
              "   'bootstrap': True,\n",
              "   'criterion': 'entropy'},\n",
              "  'CatBoost': {'iterations': 10000,\n",
              "   'learning_rate': 0.05,\n",
              "   'random_seed': 0,\n",
              "   'allow_writing_files': False,\n",
              "   'eval_metric': 'Accuracy'},\n",
              "  'ExtraTreesGini': {'n_estimators': 300,\n",
              "   'max_leaf_nodes': 15000,\n",
              "   'n_jobs': -1,\n",
              "   'random_state': 0,\n",
              "   'bootstrap': True,\n",
              "   'criterion': 'gini'},\n",
              "  'ExtraTreesEntr': {'n_estimators': 300,\n",
              "   'max_leaf_nodes': 15000,\n",
              "   'n_jobs': -1,\n",
              "   'random_state': 0,\n",
              "   'bootstrap': True,\n",
              "   'criterion': 'entropy'},\n",
              "  'NeuralNetFastAI': {'layers': None,\n",
              "   'emb_drop': 0.1,\n",
              "   'ps': 0.1,\n",
              "   'bs': 'auto',\n",
              "   'lr': 0.01,\n",
              "   'epochs': 'auto',\n",
              "   'early.stopping.min_delta': 0.0001,\n",
              "   'early.stopping.patience': 20,\n",
              "   'smoothing': 0.0},\n",
              "  'XGBoost': {'n_estimators': 10000,\n",
              "   'learning_rate': 0.1,\n",
              "   'n_jobs': -1,\n",
              "   'proc.max_category_levels': 100,\n",
              "   'objective': 'binary:logistic',\n",
              "   'booster': 'gbtree'},\n",
              "  'NeuralNetTorch': {'num_epochs': 1000,\n",
              "   'epochs_wo_improve': None,\n",
              "   'activation': 'relu',\n",
              "   'embedding_size_factor': 1.0,\n",
              "   'embed_exponent': 0.56,\n",
              "   'max_embedding_dim': 100,\n",
              "   'y_range': None,\n",
              "   'y_range_extend': 0.05,\n",
              "   'dropout_prob': 0.1,\n",
              "   'optimizer': 'adam',\n",
              "   'learning_rate': 0.0003,\n",
              "   'weight_decay': 1e-06,\n",
              "   'proc.embed_min_categories': 4,\n",
              "   'proc.impute_strategy': 'median',\n",
              "   'proc.max_category_levels': 100,\n",
              "   'proc.skew_threshold': 0.99,\n",
              "   'use_ngram_features': False,\n",
              "   'num_layers': 4,\n",
              "   'hidden_size': 128,\n",
              "   'max_batch_size': 512,\n",
              "   'use_batchnorm': False,\n",
              "   'loss_function': 'auto'},\n",
              "  'LightGBMLarge': {'learning_rate': 0.03,\n",
              "   'num_leaves': 128,\n",
              "   'feature_fraction': 0.9,\n",
              "   'min_data_in_leaf': 3},\n",
              "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
              "   'valid_stacker': True,\n",
              "   'max_base_models': 0,\n",
              "   'max_base_models_per_type': 'auto',\n",
              "   'save_bag_folds': True,\n",
              "   'stratify': 'auto',\n",
              "   'bin': 'auto',\n",
              "   'n_bins': None}},\n",
              " 'leaderboard':                   model  score_val eval_metric  pred_time_val   fit_time  \\\n",
              " 0               XGBoost     0.8848    accuracy       0.008898   0.564189   \n",
              " 1   WeightedEnsemble_L2     0.8848    accuracy       0.009901   0.659667   \n",
              " 2              CatBoost     0.8824    accuracy       0.004666  15.910002   \n",
              " 3              LightGBM     0.8824    accuracy       0.009215   0.505479   \n",
              " 4         LightGBMLarge     0.8824    accuracy       0.009531   0.749856   \n",
              " 5            LightGBMXT     0.8792    accuracy       0.012777   5.615748   \n",
              " 6       NeuralNetFastAI     0.8612    accuracy       0.022529  27.226740   \n",
              " 7      RandomForestGini     0.8612    accuracy       0.050318   1.578749   \n",
              " 8      RandomForestEntr     0.8592    accuracy       0.049396   1.560209   \n",
              " 9        NeuralNetTorch     0.8576    accuracy       0.013838  40.698632   \n",
              " 10       ExtraTreesGini     0.8528    accuracy       0.049844   0.938210   \n",
              " 11       ExtraTreesEntr     0.8520    accuracy       0.050973   0.920979   \n",
              " \n",
              "     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
              " 0                 0.008898           0.564189            1       True   \n",
              " 1                 0.001003           0.095478            2       True   \n",
              " 2                 0.004666          15.910002            1       True   \n",
              " 3                 0.009215           0.505479            1       True   \n",
              " 4                 0.009531           0.749856            1       True   \n",
              " 5                 0.012777           5.615748            1       True   \n",
              " 6                 0.022529          27.226740            1       True   \n",
              " 7                 0.050318           1.578749            1       True   \n",
              " 8                 0.049396           1.560209            1       True   \n",
              " 9                 0.013838          40.698632            1       True   \n",
              " 10                0.049844           0.938210            1       True   \n",
              " 11                0.050973           0.920979            1       True   \n",
              " \n",
              "     fit_order  \n",
              " 0           9  \n",
              " 1          12  \n",
              " 2           5  \n",
              " 3           2  \n",
              " 4          11  \n",
              " 5           1  \n",
              " 6           8  \n",
              " 7           3  \n",
              " 8           4  \n",
              " 9          10  \n",
              " 10          6  \n",
              " 11          7  }"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.fit_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "bC1EFS6rlpJU",
        "outputId": "4ef1dee9-795f-4e90-ce57-595bfa76e032"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing feature importance via permutation shuffling for 14 features using 5000 rows with 5 shuffle sets...\n",
            "\t2.69s\t= Expected runtime (0.54s per shuffle set)\n",
            "\t1.5s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>importance</th>\n",
              "      <th>stddev</th>\n",
              "      <th>p_value</th>\n",
              "      <th>n</th>\n",
              "      <th>p99_high</th>\n",
              "      <th>p99_low</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>marital-status</th>\n",
              "      <td>0.05164</td>\n",
              "      <td>0.003321</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>5</td>\n",
              "      <td>0.058478</td>\n",
              "      <td>0.044802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>capital-gain</th>\n",
              "      <td>0.04696</td>\n",
              "      <td>0.004853</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>5</td>\n",
              "      <td>0.056952</td>\n",
              "      <td>0.036968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>education-num</th>\n",
              "      <td>0.03180</td>\n",
              "      <td>0.005030</td>\n",
              "      <td>0.000073</td>\n",
              "      <td>5</td>\n",
              "      <td>0.042157</td>\n",
              "      <td>0.021443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>0.01556</td>\n",
              "      <td>0.003477</td>\n",
              "      <td>0.000280</td>\n",
              "      <td>5</td>\n",
              "      <td>0.022719</td>\n",
              "      <td>0.008401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>occupation</th>\n",
              "      <td>0.01456</td>\n",
              "      <td>0.002889</td>\n",
              "      <td>0.000177</td>\n",
              "      <td>5</td>\n",
              "      <td>0.020509</td>\n",
              "      <td>0.008611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>capital-loss</th>\n",
              "      <td>0.01260</td>\n",
              "      <td>0.001631</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>5</td>\n",
              "      <td>0.015958</td>\n",
              "      <td>0.009242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hours-per-week</th>\n",
              "      <td>0.00820</td>\n",
              "      <td>0.002135</td>\n",
              "      <td>0.000505</td>\n",
              "      <td>5</td>\n",
              "      <td>0.012597</td>\n",
              "      <td>0.003803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>workclass</th>\n",
              "      <td>0.00304</td>\n",
              "      <td>0.001780</td>\n",
              "      <td>0.009396</td>\n",
              "      <td>5</td>\n",
              "      <td>0.006705</td>\n",
              "      <td>-0.000625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>relationship</th>\n",
              "      <td>0.00212</td>\n",
              "      <td>0.001706</td>\n",
              "      <td>0.024961</td>\n",
              "      <td>5</td>\n",
              "      <td>0.005634</td>\n",
              "      <td>-0.001394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fnlwgt</th>\n",
              "      <td>0.00196</td>\n",
              "      <td>0.001499</td>\n",
              "      <td>0.021555</td>\n",
              "      <td>5</td>\n",
              "      <td>0.005047</td>\n",
              "      <td>-0.001127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>education</th>\n",
              "      <td>0.00140</td>\n",
              "      <td>0.000616</td>\n",
              "      <td>0.003544</td>\n",
              "      <td>5</td>\n",
              "      <td>0.002669</td>\n",
              "      <td>0.000131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sex</th>\n",
              "      <td>0.00104</td>\n",
              "      <td>0.001307</td>\n",
              "      <td>0.074894</td>\n",
              "      <td>5</td>\n",
              "      <td>0.003731</td>\n",
              "      <td>-0.001651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>race</th>\n",
              "      <td>0.00064</td>\n",
              "      <td>0.001889</td>\n",
              "      <td>0.245429</td>\n",
              "      <td>5</td>\n",
              "      <td>0.004529</td>\n",
              "      <td>-0.003249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>native-country</th>\n",
              "      <td>0.00052</td>\n",
              "      <td>0.000303</td>\n",
              "      <td>0.009281</td>\n",
              "      <td>5</td>\n",
              "      <td>0.001145</td>\n",
              "      <td>-0.000105</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                importance    stddev   p_value  n  p99_high   p99_low\n",
              "marital-status     0.05164  0.003321  0.000002  5  0.058478  0.044802\n",
              "capital-gain       0.04696  0.004853  0.000013  5  0.056952  0.036968\n",
              "education-num      0.03180  0.005030  0.000073  5  0.042157  0.021443\n",
              "age                0.01556  0.003477  0.000280  5  0.022719  0.008401\n",
              "occupation         0.01456  0.002889  0.000177  5  0.020509  0.008611\n",
              "capital-loss       0.01260  0.001631  0.000033  5  0.015958  0.009242\n",
              "hours-per-week     0.00820  0.002135  0.000505  5  0.012597  0.003803\n",
              "workclass          0.00304  0.001780  0.009396  5  0.006705 -0.000625\n",
              "relationship       0.00212  0.001706  0.024961  5  0.005634 -0.001394\n",
              "fnlwgt             0.00196  0.001499  0.021555  5  0.005047 -0.001127\n",
              "education          0.00140  0.000616  0.003544  5  0.002669  0.000131\n",
              "sex                0.00104  0.001307  0.074894  5  0.003731 -0.001651\n",
              "race               0.00064  0.001889  0.245429  5  0.004529 -0.003249\n",
              "native-country     0.00052  0.000303  0.009281  5  0.001145 -0.000105"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.feature_importance(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeIk6Frsf_RR",
        "outputId": "95d078da-9045-47c2-d8a9-d876360124e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.88      0.95      0.91      7451\n",
            "        >50K       0.77      0.57      0.66      2318\n",
            "\n",
            "    accuracy                           0.86      9769\n",
            "   macro avg       0.83      0.76      0.79      9769\n",
            "weighted avg       0.85      0.86      0.85      9769\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "train_encoded = encoder.fit_transform(train_data.drop(columns=[label]))\n",
        "test_encoded = encoder.transform(test_data.drop(columns=[label]))\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(train_encoded, train_data[label])\n",
        "y_pred = rf.predict(test_encoded)\n",
        "print(classification_report(test_data[label], y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtovB1jYnPjf",
        "outputId": "03fdea17-b856-41a5-8ce7-de19a38c331c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels\\ag-20251013_060826\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.4.0\n",
            "Python Version:     3.12.10\n",
            "Operating System:   Windows\n",
            "Platform Machine:   AMD64\n",
            "Platform Version:   10.0.26100\n",
            "CPU Count:          12\n",
            "Memory Avail:       8.45 GB / 31.91 GB (26.5%)\n",
            "Disk Space Avail:   192.16 GB / 476.00 GB (40.4%)\n",
            "===================================================\n",
            "Presets specified: ['best_quality']\n",
            "Using hyperparameters preset: hyperparameters='zeroshot'\n",
            "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
            "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
            "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
            "2025-10-13 03:08:30,185\tINFO worker.py:1843 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
            "\t\tContext path: \"c:\\AI\\postgrad-ai\\fase_3\\machine_learning\\auto_ml\\AutogluonModels\\ag-20251013_060826\\ds_sub_fit\\sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Running DyStack sub-fit ...\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Beginning AutoGluon training ... Time limit = 895s\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m AutoGluon will save models to \"c:\\AI\\postgrad-ai\\fase_3\\machine_learning\\auto_ml\\AutogluonModels\\ag-20251013_060826\\ds_sub_fit\\sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Train Data Rows:    34731\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Train Data Columns: 14\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Label Column:       class\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Problem Type:       binary\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Preprocessing data ...\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Using Feature Generators to preprocess the data ...\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tAvailable Memory:                    8057.54 MB\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tTrain Data (Original)  Memory Usage: 17.31 MB (0.2% of available memory)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tStage 1 Generators:\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tStage 2 Generators:\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tStage 3 Generators:\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tStage 4 Generators:\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tStage 5 Generators:\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t\t('int', ['bool']) : 1 | ['sex']\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.1s = Fit runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t14 features in original data used to generate 14 features in processed data.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tTrain Data (Processed) Memory Usage: 1.86 MB (0.0% of available memory)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Data preprocessing and feature engineering runtime = 0.15s ...\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m User-specified model hyperparameters to be fit:\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m {\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m }\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 596.44s of the 894.87s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.25%)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.8687\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t2.33s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.8s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 588.18s of the 886.62s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.25%)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.8759\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t1.32s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.33s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 584.09s of the 882.53s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.8569\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t2.13s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.92s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 580.76s of the 879.19s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.8568\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t1.29s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.86s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 578.34s of the 876.78s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=5.42%)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.8738\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t98.15s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.05s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 477.52s of the 775.95s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.8492\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.94s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t1.02s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 475.21s of the 773.65s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.85\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.92s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t1.08s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 472.86s of the 771.29s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.34%)\n",
            "\u001b[36m(_ray_fit pid=22756)\u001b[0m No improvement since epoch 5: early stopping\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.8592\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t39.93s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.41s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 430.09s of the 728.53s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.50%)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.8748\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t5.31s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.26s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 421.44s of the 719.88s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.17%)\n",
            "\u001b[36m(_ray_fit pid=19968)\u001b[0m c:\\AI\\postgrad-ai\\.venv\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
            "\u001b[36m(_ray_fit pid=19968)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.8576\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t81.78s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.21s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 336.99s of the 635.43s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.47%)\n",
            "\u001b[36m(_ray_fit pid=7144)\u001b[0m c:\\AI\\postgrad-ai\\.venv\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\u001b[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=7144)\u001b[0m   warnings.warn(\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.8749\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t1.84s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.48s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 332.19s of the 630.62s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=5.92%)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.8736\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t38.71s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.04s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 290.58s of the 589.01s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.16%)\n",
            "\u001b[36m(_ray_fit pid=22944)\u001b[0m c:\\AI\\postgrad-ai\\.venv\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
            "\u001b[36m(_ray_fit pid=22944)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.8518\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t65.3s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.25s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 222.62s of the 521.05s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.30%)\n",
            "\u001b[36m(_ray_fit pid=26132)\u001b[0m c:\\AI\\postgrad-ai\\.venv\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=26132)\u001b[0m   warnings.warn(\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=15420)\u001b[0m [1000]\tvalid_set's binary_error: 0.1269\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.8743\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t3.37s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t1.06s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 216.00s of the 514.44s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.29%)\n",
            "\u001b[36m(_ray_fit pid=9348)\u001b[0m No improvement since epoch 13: early stopping\n",
            "\u001b[36m(_ray_fit pid=25084)\u001b[0m No improvement since epoch 18: early stopping\n",
            "\u001b[36m(_ray_fit pid=12656)\u001b[0m No improvement since epoch 19: early stopping\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.859\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t147.07s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.82s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 66.28s of the 364.71s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=5.73%)\n",
            "\u001b[36m(_ray_fit pid=24640)\u001b[0m \tRan out of time, early stopping on iteration 510.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.874\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t53.2s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.07s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 10.34s of the 308.78s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.22%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=25448)\u001b[0m [1000]\tvalid_set's binary_error: 0.130154\n",
            "\u001b[36m(_ray_fit pid=10824)\u001b[0m [1000]\tvalid_set's binary_error: 0.138185\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.8654\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t5.67s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t1.78s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 1.29s of the 299.72s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.16%)\n",
            "\u001b[36m(_ray_fit pid=25032)\u001b[0m \tRan out of time, early stopping on iteration 517.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tTime limit exceeded... Skipping NeuralNetTorch_r22_BAG_L1.\n",
            "\u001b[36m(_ray_fit pid=16792)\u001b[0m \tWarning: Model has no time left to train, skipping model... (Time Left = -0.4s)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 295.36s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L1': 1.0}\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.8759\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.38s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.0s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 294.95s of the 294.91s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.45%)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.8752\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t1.58s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.13s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 290.66s of the 290.61s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.54%)\n",
            "\u001b[36m(_ray_fit pid=25276)\u001b[0m \tWarning: Model has no time left to train, skipping model... (Time Left = -0.4s)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.8764\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t1.5s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.08s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 285.92s of the 285.87s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.8738\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t4.13s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.99s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 280.58s of the 280.53s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.875\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t4.69s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.87s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 274.82s of the 274.78s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=5.45%)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.8765\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t30.68s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.04s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 241.46s of the 241.42s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.8746\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t1.17s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t1.03s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 238.99s of the 238.95s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.8751\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.94s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t1.01s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 236.77s of the 236.72s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.63%)\n",
            "\u001b[36m(_ray_fit pid=23948)\u001b[0m No improvement since epoch 2: early stopping\n",
            "\u001b[36m(_ray_fit pid=25284)\u001b[0m No improvement since epoch 7: early stopping\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.8756\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t41.95s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.57s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: XGBoost_BAG_L2 ... Training model for up to 192.02s of the 191.98s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.50%)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.8771\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t4.51s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.19s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 184.56s of the 184.52s of remaining time.\n",
            "\u001b[36m(_ray_fit pid=27348)\u001b[0m No improvement since epoch 8: early stopping\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
            "\u001b[36m(_ray_fit pid=22832)\u001b[0m c:\\AI\\postgrad-ai\\.venv\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
            "\u001b[36m(_ray_fit pid=22832)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.8749\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t61.32s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.38s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 120.55s of the 120.50s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.55%)\n",
            "\u001b[36m(_ray_fit pid=23424)\u001b[0m c:\\AI\\postgrad-ai\\.venv\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=23424)\u001b[0m   warnings.warn(\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.8771\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t3.56s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.21s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 114.02s of the 113.97s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.69%)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.8765\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t21.75s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.04s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 89.61s of the 89.56s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
            "\u001b[36m(_ray_fit pid=24840)\u001b[0m c:\\AI\\postgrad-ai\\.venv\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
            "\u001b[36m(_ray_fit pid=24840)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(_ray_fit pid=25104)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 58)\n",
            "\u001b[36m(_ray_fit pid=27020)\u001b[0m c:\\AI\\postgrad-ai\\.venv\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=27020)\u001b[0m   warnings.warn(\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.8754\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t73.83s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.37s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 13.11s of the 13.07s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.40%)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.8765\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t2.15s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.24s\t = Validation runtime\n",
            "\u001b[36m(_ray_fit pid=27020)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 58)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 7.74s of remaining time.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tEnsemble Weights: {'LightGBMLarge_BAG_L2': 1.0}\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.8771\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.71s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \t0.0s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m AutoGluon training complete, total runtime = 888.01s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 598.9 rows/s (4342 batch size)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Enabling decision threshold calibration (calibrate_decision_threshold='auto', metric is valid, problem_type is 'binary')\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Calibrating decision threshold to optimize metric accuracy | Checking 51 thresholds...\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Calibrating decision threshold via fine-grained search | Checking 38 thresholds...\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tBase Threshold: 0.500\t| val: 0.8771\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m \tBest Threshold: 0.500\t| val: 0.8771\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\AI\\postgrad-ai\\fase_3\\machine_learning\\auto_ml\\AutogluonModels\\ag-20251013_060826\\ds_sub_fit\\sub_fit_ho\")\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=16792, ip=127.0.0.1)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m   File \"python\\\\ray\\\\_raylet.pyx\", line 1895, in ray._raylet.execute_task\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m   File \"c:\\AI\\postgrad-ai\\.venv\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 446, in _ray_fit\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m   File \"c:\\AI\\postgrad-ai\\.venv\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 1056, in fit\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m     raise TimeLimitExceeded\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n",
            "\u001b[36m(_dystack pid=17012)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
            "Leaderboard on holdout data (DyStack):\n",
            "                          model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0        NeuralNetFastAI_BAG_L2       0.877706   0.875615    accuracy        5.216028      10.993500  591.207869                 0.388917                0.566400          41.948135            2       True         26\n",
            "1     NeuralNetTorch_r79_BAG_L2       0.877246   0.875443    accuracy        5.570104      10.796713  623.093699                 0.742993                0.369613          73.833964            2       True         31\n",
            "2          LightGBMLarge_BAG_L1       0.876785   0.874867    accuracy        0.178839       0.478687    1.835830                 0.178839                0.478687           1.835830            1       True         11\n",
            "3          CatBoost_r177_BAG_L2       0.876785   0.876450    accuracy        5.254400      10.466594  571.010468                 0.427289                0.039494          21.750734            2       True         30\n",
            "4         NeuralNetTorch_BAG_L2       0.876785   0.874867    accuracy        5.571363      10.802306  610.575649                 0.744252                0.375206          61.315914            2       True         28\n",
            "5                XGBoost_BAG_L1       0.876555   0.874809    accuracy        0.245327       0.258441    5.305396                 0.245327                0.258441           5.305396            1       True          9\n",
            "6               CatBoost_BAG_L1       0.876555   0.873830    accuracy        0.394006       0.049199   98.151581                 0.394006                0.049199          98.151581            1       True          5\n",
            "7             LightGBMXT_BAG_L2       0.876324   0.875184    accuracy        4.873913      10.559308  550.839723                 0.046802                0.132208           1.579989            2       True         19\n",
            "8               LightGBM_BAG_L2       0.876094   0.876364    accuracy        4.864735      10.511648  550.755446                 0.037624                0.084548           1.495712            2       True         20\n",
            "9            CatBoost_r9_BAG_L1       0.875403   0.874003    accuracy        0.104452       0.072211   53.202404                 0.104452                0.072211          53.202404            1       True         16\n",
            "10              CatBoost_BAG_L2       0.875403   0.876479    accuracy        4.852540      10.471013  579.935266                 0.025429                0.043913          30.675531            2       True         23\n",
            "11               XGBoost_BAG_L2       0.875403   0.877055    accuracy        4.973154      10.619341  553.766476                 0.146043                0.192241           4.506742            2       True         27\n",
            "12         CatBoost_r177_BAG_L1       0.875173   0.873571    accuracy        0.039766       0.044818   38.708509                 0.039766                0.044818          38.708509            1       True         12\n",
            "13        ExtraTreesGini_BAG_L2       0.875173   0.874550    accuracy        5.047877      11.456264  550.434585                 0.220766                1.029164           1.174850            2       True         24\n",
            "14         LightGBMLarge_BAG_L2       0.874712   0.877084    accuracy        5.335670      10.642062  552.819599                 0.508559                0.214962           3.559865            2       True         29\n",
            "15          WeightedEnsemble_L3       0.874712   0.877084    accuracy        5.345583      10.643499  553.528104                 0.009912                0.001437           0.708505            3       True         33\n",
            "16        ExtraTreesEntr_BAG_L2       0.874482   0.875068    accuracy        5.049424      11.437768  550.203589                 0.222313                1.010668           0.943855            2       True         25\n",
            "17              LightGBM_BAG_L1       0.874021   0.875875    accuracy        0.061888       0.331218    1.322291                 0.061888                0.331218           1.322291            1       True          2\n",
            "18          WeightedEnsemble_L2       0.874021   0.875875    accuracy        0.062888       0.332230    1.701865                 0.001000                0.001012           0.379574            2       True         18\n",
            "19         LightGBM_r131_BAG_L2       0.873100   0.876537    accuracy        5.563874      10.671932  551.405536                 0.736763                0.244832           2.145802            2       True         32\n",
            "20         LightGBM_r131_BAG_L1       0.872639   0.874349    accuracy        0.213310       1.058834    3.372477                 0.213310                1.058834           3.372477            1       True         14\n",
            "21      RandomForestEntr_BAG_L2       0.872639   0.874953    accuracy        4.982142      11.301363  553.953498                 0.155031                0.874263           4.693764            2       True         22\n",
            "22      RandomForestGini_BAG_L2       0.871718   0.873802    accuracy        5.013254      11.413745  553.391681                 0.186143                0.986645           4.131947            2       True         21\n",
            "23            LightGBMXT_BAG_L1       0.868033   0.868734    accuracy        0.298543       0.797616    2.333119                 0.298543                0.797616           2.333119            1       True          1\n",
            "24          LightGBM_r96_BAG_L1       0.866651   0.865423    accuracy        0.303847       1.777635    5.668953                 0.303847                1.777635           5.668953            1       True         17\n",
            "25  NeuralNetFastAI_r191_BAG_L1       0.862045   0.859031    accuracy        0.530748       0.820752  147.072944                 0.530748                0.820752         147.072944            1       True         15\n",
            "26       NeuralNetFastAI_BAG_L1       0.861815   0.859204    accuracy        0.929074       0.406719   39.925436                 0.929074                0.406719          39.925436            1       True          8\n",
            "27        NeuralNetTorch_BAG_L1       0.861124   0.857562    accuracy        0.183572       0.205077   81.783034                 0.183572                0.205077          81.783034            1       True         10\n",
            "28      RandomForestEntr_BAG_L1       0.859512   0.856785    accuracy        0.240052       0.856009    1.289405                 0.240052                0.856009           1.289405            1       True          4\n",
            "29      RandomForestGini_BAG_L1       0.858591   0.856871    accuracy        0.252376       0.919376    2.130193                 0.252376                0.919376           2.130193            1       True          3\n",
            "30        ExtraTreesEntr_BAG_L1       0.856287   0.849961    accuracy        0.319875       1.084683    0.920774                 0.319875                1.084683           0.920774            1       True          7\n",
            "31        ExtraTreesGini_BAG_L1       0.855596   0.849155    accuracy        0.329535       1.017303    0.935865                 0.329535                1.017303           0.935865            1       True          6\n",
            "32    NeuralNetTorch_r79_BAG_L1       0.854215   0.851833    accuracy        0.201901       0.248522   65.301523                 0.201901                0.248522          65.301523            1       True         13\n",
            "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
            "\t905s\t = DyStack   runtime |\t2695s\t = Remaining runtime\n",
            "Starting main fit with num_stack_levels=1.\n",
            "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
            "Beginning AutoGluon training ... Time limit = 2695s\n",
            "AutoGluon will save models to \"c:\\AI\\postgrad-ai\\fase_3\\machine_learning\\auto_ml\\AutogluonModels\\ag-20251013_060826\"\n",
            "Train Data Rows:    39073\n",
            "Train Data Columns: 14\n",
            "Label Column:       class\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11773.31 MB\n",
            "\tTrain Data (Original)  Memory Usage: 19.48 MB (0.2% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('int', ['bool']) : 1 | ['sex']\n",
            "\t0.2s = Fit runtime\n",
            "\t14 features in original data used to generate 14 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 2.09 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.24s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1796.05s of the 2694.74s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.16%)\n",
            "\t0.8683\t = Validation score   (accuracy)\n",
            "\t1.66s\t = Training   runtime\n",
            "\t0.54s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1791.47s of the 2690.16s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.17%)\n",
            "\t0.8745\t = Validation score   (accuracy)\n",
            "\t1.74s\t = Training   runtime\n",
            "\t0.27s\t = Validation runtime\n",
            "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 1787.37s of the 2686.06s of remaining time.\n",
            "\t0.8569\t = Validation score   (accuracy)\n",
            "\t1.94s\t = Training   runtime\n",
            "\t0.99s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 1784.14s of the 2682.83s of remaining time.\n",
            "\t0.8571\t = Validation score   (accuracy)\n",
            "\t1.48s\t = Training   runtime\n",
            "\t0.96s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1781.44s of the 2680.13s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.53%)\n",
            "\t0.8738\t = Validation score   (accuracy)\n",
            "\t101.65s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 1677.60s of the 2576.29s of remaining time.\n",
            "\t0.8509\t = Validation score   (accuracy)\n",
            "\t1.0s\t = Training   runtime\n",
            "\t1.09s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 1675.14s of the 2573.83s of remaining time.\n",
            "\t0.8519\t = Validation score   (accuracy)\n",
            "\t1.02s\t = Training   runtime\n",
            "\t1.14s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1672.62s of the 2571.31s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.16%)\n",
            "\t0.859\t = Validation score   (accuracy)\n",
            "\t44.82s\t = Training   runtime\n",
            "\t0.45s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1625.63s of the 2524.32s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
            "\t0.8758\t = Validation score   (accuracy)\n",
            "\t6.27s\t = Training   runtime\n",
            "\t0.33s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1616.18s of the 2514.87s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
            "\t0.8586\t = Validation score   (accuracy)\n",
            "\t92.45s\t = Training   runtime\n",
            "\t0.22s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1521.53s of the 2420.22s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.26%)\n",
            "\t0.8738\t = Validation score   (accuracy)\n",
            "\t2.81s\t = Training   runtime\n",
            "\t0.7s\t = Validation runtime\n",
            "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 1516.13s of the 2414.82s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.95%)\n",
            "\t0.8749\t = Validation score   (accuracy)\n",
            "\t57.96s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 1455.67s of the 2354.36s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
            "\t0.8521\t = Validation score   (accuracy)\n",
            "\t75.88s\t = Training   runtime\n",
            "\t0.28s\t = Validation runtime\n",
            "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 1377.17s of the 2275.86s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
            "\t0.8748\t = Validation score   (accuracy)\n",
            "\t3.48s\t = Training   runtime\n",
            "\t1.16s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 1371.04s of the 2269.73s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
            "\t0.8604\t = Validation score   (accuracy)\n",
            "\t155.98s\t = Training   runtime\n",
            "\t1.02s\t = Validation runtime\n",
            "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 1212.70s of the 2111.39s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.63%)\n",
            "\t0.8753\t = Validation score   (accuracy)\n",
            "\t93.45s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 1116.85s of the 2015.54s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
            "\t0.8658\t = Validation score   (accuracy)\n",
            "\t5.1s\t = Training   runtime\n",
            "\t1.66s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 1109.07s of the 2007.76s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
            "\t0.8597\t = Validation score   (accuracy)\n",
            "\t164.8s\t = Training   runtime\n",
            "\t0.37s\t = Validation runtime\n",
            "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 942.11s of the 1840.80s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.41%)\n",
            "\t0.8745\t = Validation score   (accuracy)\n",
            "\t11.99s\t = Training   runtime\n",
            "\t1.64s\t = Validation runtime\n",
            "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 927.16s of the 1825.85s of remaining time.\n",
            "\t0.8545\t = Validation score   (accuracy)\n",
            "\t1.52s\t = Training   runtime\n",
            "\t1.0s\t = Validation runtime\n",
            "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 924.35s of the 1823.04s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.34%)\n",
            "\t0.8739\t = Validation score   (accuracy)\n",
            "\t163.47s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 758.71s of the 1657.40s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
            "\t0.8601\t = Validation score   (accuracy)\n",
            "\t21.04s\t = Training   runtime\n",
            "\t0.23s\t = Validation runtime\n",
            "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 735.52s of the 1634.21s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.83%)\n",
            "\t0.8721\t = Validation score   (accuracy)\n",
            "\t144.42s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 588.14s of the 1486.83s of remaining time.\n",
            "\t0.8549\t = Validation score   (accuracy)\n",
            "\t3.09s\t = Training   runtime\n",
            "\t0.92s\t = Validation runtime\n",
            "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 583.88s of the 1482.57s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.21%)\n",
            "\t0.8673\t = Validation score   (accuracy)\n",
            "\t4.61s\t = Training   runtime\n",
            "\t1.02s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 576.32s of the 1475.01s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
            "\t0.857\t = Validation score   (accuracy)\n",
            "\t105.29s\t = Training   runtime\n",
            "\t0.91s\t = Validation runtime\n",
            "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 468.52s of the 1367.21s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.18%)\n",
            "\t0.8762\t = Validation score   (accuracy)\n",
            "\t7.86s\t = Training   runtime\n",
            "\t0.38s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 457.33s of the 1356.02s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
            "\t0.8532\t = Validation score   (accuracy)\n",
            "\t127.26s\t = Training   runtime\n",
            "\t0.37s\t = Validation runtime\n",
            "Fitting model: LightGBM_r130_BAG_L1 ... Training model for up to 327.89s of the 1226.58s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.17%)\n",
            "\t0.8739\t = Validation score   (accuracy)\n",
            "\t2.76s\t = Training   runtime\n",
            "\t0.78s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 322.22s of the 1220.91s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
            "\t0.8593\t = Validation score   (accuracy)\n",
            "\t69.74s\t = Training   runtime\n",
            "\t0.23s\t = Validation runtime\n",
            "Fitting model: CatBoost_r50_BAG_L1 ... Training model for up to 249.76s of the 1148.45s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.29%)\n",
            "\t0.8743\t = Validation score   (accuracy)\n",
            "\t30.07s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_r11_BAG_L1 ... Training model for up to 217.44s of the 1116.13s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
            "\t0.8551\t = Validation score   (accuracy)\n",
            "\t176.39s\t = Training   runtime\n",
            "\t1.38s\t = Validation runtime\n",
            "Fitting model: XGBoost_r194_BAG_L1 ... Training model for up to 38.92s of the 937.61s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.21%)\n",
            "\t0.8754\t = Validation score   (accuracy)\n",
            "\t2.64s\t = Training   runtime\n",
            "\t0.32s\t = Validation runtime\n",
            "Fitting model: ExtraTrees_r172_BAG_L1 ... Training model for up to 33.83s of the 932.52s of remaining time.\n",
            "\t0.8632\t = Validation score   (accuracy)\n",
            "\t1.94s\t = Training   runtime\n",
            "\t0.93s\t = Validation runtime\n",
            "Fitting model: CatBoost_r69_BAG_L1 ... Training model for up to 30.79s of the 929.48s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.28%)\n",
            "\t0.8701\t = Validation score   (accuracy)\n",
            "\t25.18s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_r103_BAG_L1 ... Training model for up to 3.23s of the 901.92s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
            "\t0.8473\t = Validation score   (accuracy)\n",
            "\t7.38s\t = Training   runtime\n",
            "\t0.6s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 891.34s of remaining time.\n",
            "\tEnsemble Weights: {'XGBoost_r89_BAG_L1': 0.958, 'CatBoost_r13_BAG_L1': 0.042}\n",
            "\t0.8762\t = Validation score   (accuracy)\n",
            "\t0.87s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 890.44s of the 890.35s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.38%)\n",
            "\t0.8768\t = Validation score   (accuracy)\n",
            "\t2.57s\t = Training   runtime\n",
            "\t0.14s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 885.38s of the 885.29s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.37%)\n",
            "\t0.8773\t = Validation score   (accuracy)\n",
            "\t3.26s\t = Training   runtime\n",
            "\t0.14s\t = Validation runtime\n",
            "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 879.51s of the 879.42s of remaining time.\n",
            "\t0.876\t = Validation score   (accuracy)\n",
            "\t6.69s\t = Training   runtime\n",
            "\t1.13s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 871.49s of the 871.40s of remaining time.\n",
            "\t0.8761\t = Validation score   (accuracy)\n",
            "\t8.42s\t = Training   runtime\n",
            "\t1.17s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L2 ... Training model for up to 861.72s of the 861.63s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.72%)\n",
            "\t0.8767\t = Validation score   (accuracy)\n",
            "\t35.87s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 823.77s of the 823.67s of remaining time.\n",
            "\t0.8767\t = Validation score   (accuracy)\n",
            "\t1.23s\t = Training   runtime\n",
            "\t1.31s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 820.96s of the 820.87s of remaining time.\n",
            "\t0.8766\t = Validation score   (accuracy)\n",
            "\t1.24s\t = Training   runtime\n",
            "\t1.49s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 817.96s of the 817.87s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.48%)\n",
            "\t0.8768\t = Validation score   (accuracy)\n",
            "\t47.77s\t = Training   runtime\n",
            "\t0.52s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L2 ... Training model for up to 768.05s of the 767.95s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.49%)\n",
            "\t0.8772\t = Validation score   (accuracy)\n",
            "\t5.98s\t = Training   runtime\n",
            "\t0.23s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 759.18s of the 759.09s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.24%)\n",
            "\t0.8769\t = Validation score   (accuracy)\n",
            "\t51.22s\t = Training   runtime\n",
            "\t0.6s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 705.82s of the 705.73s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.53%)\n",
            "\t0.8779\t = Validation score   (accuracy)\n",
            "\t5.6s\t = Training   runtime\n",
            "\t0.21s\t = Validation runtime\n",
            "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 697.71s of the 697.62s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.47%)\n",
            "\t0.8776\t = Validation score   (accuracy)\n",
            "\t26.97s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 668.53s of the 668.43s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.24%)\n",
            "\t0.8771\t = Validation score   (accuracy)\n",
            "\t104.3s\t = Training   runtime\n",
            "\t0.52s\t = Validation runtime\n",
            "Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 561.78s of the 561.69s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.36%)\n",
            "\t0.8772\t = Validation score   (accuracy)\n",
            "\t4.46s\t = Training   runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 555.20s of the 555.10s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.44%)\n",
            "\t0.877\t = Validation score   (accuracy)\n",
            "\t138.97s\t = Training   runtime\n",
            "\t0.83s\t = Validation runtime\n",
            "Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 414.07s of the 413.97s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.82%)\n",
            "\t0.8772\t = Validation score   (accuracy)\n",
            "\t43.27s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: LightGBM_r96_BAG_L2 ... Training model for up to 368.62s of the 368.53s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.28%)\n",
            "\t0.8758\t = Validation score   (accuracy)\n",
            "\t2.84s\t = Training   runtime\n",
            "\t0.29s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_r22_BAG_L2 ... Training model for up to 363.67s of the 363.58s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.25%)\n",
            "\t0.8767\t = Validation score   (accuracy)\n",
            "\t107.05s\t = Training   runtime\n",
            "\t0.69s\t = Validation runtime\n",
            "Fitting model: XGBoost_r33_BAG_L2 ... Training model for up to 254.40s of the 254.31s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.20%)\n",
            "\t0.8771\t = Validation score   (accuracy)\n",
            "\t20.82s\t = Training   runtime\n",
            "\t0.77s\t = Validation runtime\n",
            "Fitting model: ExtraTrees_r42_BAG_L2 ... Training model for up to 231.17s of the 231.07s of remaining time.\n",
            "\t0.8764\t = Validation score   (accuracy)\n",
            "\t3.37s\t = Training   runtime\n",
            "\t1.17s\t = Validation runtime\n",
            "Fitting model: CatBoost_r137_BAG_L2 ... Training model for up to 226.42s of the 226.33s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.29%)\n",
            "\t0.8765\t = Validation score   (accuracy)\n",
            "\t29.96s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_r102_BAG_L2 ... Training model for up to 194.29s of the 194.20s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.43%)\n",
            "\t0.8764\t = Validation score   (accuracy)\n",
            "\t22.47s\t = Training   runtime\n",
            "\t0.25s\t = Validation runtime\n",
            "Fitting model: CatBoost_r13_BAG_L2 ... Training model for up to 169.65s of the 169.55s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.00%)\n",
            "\t0.8764\t = Validation score   (accuracy)\n",
            "\t46.44s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: RandomForest_r195_BAG_L2 ... Training model for up to 120.30s of the 120.21s of remaining time.\n",
            "\t0.8758\t = Validation score   (accuracy)\n",
            "\t35.68s\t = Training   runtime\n",
            "\t1.08s\t = Validation runtime\n",
            "Fitting model: LightGBM_r188_BAG_L2 ... Training model for up to 83.35s of the 83.26s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.51%)\n",
            "\t0.8773\t = Validation score   (accuracy)\n",
            "\t3.16s\t = Training   runtime\n",
            "\t0.35s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_r145_BAG_L2 ... Training model for up to 78.05s of the 77.96s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.45%)\n",
            "\t0.8769\t = Validation score   (accuracy)\n",
            "\t63.88s\t = Training   runtime\n",
            "\t0.93s\t = Validation runtime\n",
            "Fitting model: XGBoost_r89_BAG_L2 ... Training model for up to 11.41s of the 11.32s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.52%)\n",
            "\t0.8766\t = Validation score   (accuracy)\n",
            "\t5.09s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 2.93s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBMLarge_BAG_L2': 1.0}\n",
            "\t0.8779\t = Validation score   (accuracy)\n",
            "\t1.13s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 2693.22s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 298.4 rows/s (4885 batch size)\n",
            "Enabling decision threshold calibration (calibrate_decision_threshold='auto', metric is valid, problem_type is 'binary')\n",
            "Calibrating decision threshold to optimize metric accuracy | Checking 51 thresholds...\n",
            "Calibrating decision threshold via fine-grained search | Checking 38 thresholds...\n",
            "\tBase Threshold: 0.500\t| val: 0.8779\n",
            "\tBest Threshold: 0.500\t| val: 0.8779\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\AI\\postgrad-ai\\fase_3\\machine_learning\\auto_ml\\AutogluonModels\\ag-20251013_060826\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.89      0.95      0.92      7451\n",
            "        >50K       0.80      0.63      0.71      2318\n",
            "\n",
            "    accuracy                           0.88      9769\n",
            "   macro avg       0.85      0.79      0.81      9769\n",
            "weighted avg       0.87      0.88      0.87      9769\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predictor = TabularPredictor(label=label).fit(train_data, presets='best_quality', time_limit=3600)\n",
        "y_pred2 = predictor.predict(test_data.drop(columns=[label]))\n",
        "\n",
        "print(classification_report(test_data[label], y_pred2))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
